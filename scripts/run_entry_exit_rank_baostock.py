#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ä½¿ç”¨ baostock 5 åˆ†é’Ÿè¡Œæƒ…è®¡ç®— EntryRank / ExitRankï¼ˆå…¨é‡æ ‡çš„ï¼‰ï¼Œå¸¦è¡Œæƒ…ç¼“å­˜ + ç»“æœç¼“å­˜
- å…¨ä½“äº¤æ˜“: TÎ±_global=234 åˆ†é’Ÿ
- è¶…çŸ­å•(æŒä»“<=10åˆ†é’Ÿ): TÎ±_short=5 åˆ†é’Ÿ
- è¡Œæƒ…ç¼“å­˜: data/cache/baostock_5min/{code}.parquetï¼ˆå­˜åœ¨åˆ™å¤ç”¨ï¼Œä¸å†æ‹‰å–ï¼‰
- ç»“æœç¼“å­˜: data/cache/entry_exit_rank_baostock_result.jsonï¼ˆå­˜åœ¨åˆ™ç›´æ¥ç”Ÿæˆé¡µé¢ï¼›å¦‚ç®—æ³•æˆ–å‚æ•°æ”¹åŠ¨ï¼Œè¯· --recomputeï¼‰
è¾“å‡º:
- reports/entry_exit_rank_baostock_full.html (ç›´æ–¹å›¾é¡µé¢)
- reports/entry_exit_rank_baostock_full.txt  (æ ·æœ¬è®¡æ•°)
è¿è¡Œæ–¹å¼ï¼ˆåœ¨ä»“åº“æ ¹ç›®å½•ï¼‰:
HTTP_PROXY= HTTPS_PROXY= http_proxy= https_proxy= /home/ubuntu/.conda/envs/quant_env/bin/python scripts/run_entry_exit_rank_baostock.py
å¼ºåˆ¶é‡ç®—ï¼ˆå¿½ç•¥ç»“æœç¼“å­˜ï¼‰:
HTTP_PROXY= HTTPS_PROXY= http_proxy= https_proxy= /home/ubuntu/.conda/envs/quant_env/bin/python scripts/run_entry_exit_rank_baostock.py --recompute
"""
import argparse
import baostock as bs
import json
import pandas as pd
import numpy as np
from datetime import timedelta
from pathlib import Path
import plotly.graph_objects as go

T_GLOBAL = 234      # å…¨ä½“äº¤æ˜“çª—å£ï¼ˆåˆ†é’Ÿï¼‰
T_SHORT = 5         # è¶…çŸ­å•çª—å£ï¼ˆåˆ†é’Ÿï¼‰
PAIRS_PATH = Path('data/paired_trades_fifo.parquet')
REPORT_HTML = Path('reports/entry_exit_rank_baostock_full.html')
REPORT_TXT = Path('reports/entry_exit_rank_baostock_full.txt')
COPY_HTML_TARGETS = [
    Path('reports/visualization_analysis/entry_exit_rank_baostock_full.html'),
    Path('docs/entry_exit_rank_baostock_full.html'),
]
CACHE_DIR = Path('data/cache/baostock_5min')
RESULT_CACHE = Path('data/cache/entry_exit_rank_baostock_result.json')

parser = argparse.ArgumentParser(description='è®¡ç®— Entry/ExitRank (baostock 5min)')
parser.add_argument('--recompute', action='store_true', help='å¿½ç•¥ç»“æœç¼“å­˜ï¼Œé‡æ–°è®¡ç®—')
args = parser.parse_args()
use_result_cache = RESULT_CACHE.exists() and (not args.recompute)


def summarize_hist(data, key, title, bins=30):
    arr = np.asarray(data, dtype=float)
    arr = arr[np.isfinite(arr)]
    if arr.size == 0:
        return None
    counts, edges = np.histogram(arr, bins=bins, range=(0, 1))
    stats = {
        "size": int(arr.size),
        "mean": float(arr.mean()),
        "median": float(np.median(arr)),
        "p25": float(np.percentile(arr, 25)),
        "p75": float(np.percentile(arr, 75)),
    }
    return {
        "key": key,
        "title": title,
        "counts": counts.tolist(),
        "edges": edges.tolist(),
        "stats": stats,
    }


def fig_from_hist(hist):
    edges = np.asarray(hist["edges"], dtype=float)
    counts = np.asarray(hist["counts"], dtype=float)
    total = counts.sum()
    probs = counts / total if total > 0 else counts
    centers = (edges[:-1] + edges[1:]) / 2
    widths = edges[1:] - edges[:-1]
    st = hist["stats"]
    stats_str = f"æ ·æœ¬: {st['size']:,} | å‡å€¼: {st['mean']:.3f} | ä¸­ä½æ•°: {st['median']:.3f} | P25/P75: {st['p25']:.3f}/{st['p75']:.3f}"
    fig = go.Figure(go.Bar(x=centers, y=probs, width=widths, marker=dict(color='teal')))
    fig.update_layout(
        title=f"{hist['title']}<br><sub>{stats_str}</sub>",
        xaxis_title='Rank (0=å¥½)',
        yaxis_title='æ¯”ä¾‹',
        bargap=0.05,
    )
    return fig


def format_stats(stats):
    if not stats or stats.get("size", 0) == 0:
        return "æ— æ•°æ®"
    return f"æ ·æœ¬ {stats['size']:,} | å‡å€¼ {stats['mean']:.3f} | ä¸­ä½æ•° {stats['median']:.3f} | P25/P75 {stats['p25']:.3f}/{stats['p75']:.3f}"


def trading_minutes(o, c):
    open_ts = pd.Timestamp(o); close_ts = pd.Timestamp(c)
    open_date = open_ts.date(); close_date = close_ts.date()
    M1, M2, A1, A2 = 570, 690, 780, 900
    open_min = open_ts.hour * 60 + open_ts.minute
    close_min = close_ts.hour * 60 + close_ts.minute
    if open_date == close_date:
        return max(0, min(M2, close_min) - max(M1, open_min)) + max(0, min(A2, close_min) - max(A1, open_min))
    open_m = max(0, M2 - max(M1, open_min)) + max(0, A2 - max(A1, open_min))
    close_m = max(0, min(M2, close_min) - M1) + max(0, min(A2, close_min) - A1)
    middle_days = np.busday_count(np.array(open_date, dtype='datetime64[D]') + np.timedelta64(1, 'D'), np.array(close_date, dtype='datetime64[D]'), weekmask='1111100')
    return open_m + close_m + int(middle_days) * 240


sample_counts = {}
stats_map = {}
figs = []
T_GLOBAL_USE = T_GLOBAL
T_SHORT_USE = T_SHORT

if use_result_cache:
    print('ğŸ—‚ï¸ æ£€æµ‹åˆ°ç»“æœç¼“å­˜ï¼Œç›´æ¥ç”Ÿæˆé¡µé¢ï¼ˆå¦‚éœ€é‡ç®—è¯·åŠ  --recomputeï¼‰', flush=True)
    payload = json.loads(RESULT_CACHE.read_text(encoding='utf-8'))
    meta = payload.get('meta', {})
    hists = payload.get('hists', [])
    T_GLOBAL_USE = meta.get('t_global', T_GLOBAL)
    T_SHORT_USE = meta.get('t_short', T_SHORT)
    sample_counts = meta.get('sample_counts', {})
    stats_map = {h['key']: h.get('stats', {}) for h in hists}
    figs = [fig_from_hist(h) for h in hists]
else:
    print('âœ… åŠ è½½é…å¯¹äº¤æ˜“æ•°æ®...', flush=True)
    pairs = pd.read_parquet(PAIRS_PATH, columns=['code', 'trade_type', 'buy_timestamp', 'sell_timestamp', 'buy_price', 'sell_price'])
    for col in ['buy_timestamp', 'sell_timestamp']:
        if not pd.api.types.is_datetime64_any_dtype(pairs[col]):
            pairs[col] = pd.to_datetime(pairs[col])

    short_mask = pairs['trade_type'] == 'short'
    pairs['open_timestamp'] = pairs['buy_timestamp'].where(~short_mask, pairs['sell_timestamp'])
    pairs['close_timestamp'] = pairs['sell_timestamp'].where(~short_mask, pairs['buy_timestamp'])
    pairs['open_price'] = pairs['buy_price'].where(~short_mask, pairs['sell_price'])
    pairs['close_price'] = pairs['sell_price'].where(~short_mask, pairs['buy_price'])
    pairs['holding_minutes_trading'] = [trading_minutes(o, c) for o, c in zip(pairs['open_timestamp'], pairs['close_timestamp'])]

    # æŒ‰æ ‡çš„æ„å»ºæ—¥æœŸèŒƒå›´ï¼ŒæŒ‰äº¤æ˜“æ¡æ•°æ’åº
    code_ranges = {}
    for code, g in pairs.groupby('code'):
        start = g[['open_timestamp', 'close_timestamp']].min().min().date()
        end = g[['open_timestamp', 'close_timestamp']].max().max().date()
        code_ranges[code] = (start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))
    codes_sorted = sorted(code_ranges.keys(), key=lambda x: len(pairs[pairs['code'] == x]), reverse=True)
    print(f'ğŸ“ˆ æ ‡çš„æ•°é‡: {len(codes_sorted)}', flush=True)

    entries_g = []; exits_g = []; entries_s = []; exits_s = []

    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_files = {code: CACHE_DIR / f"{code.replace('.', '_')}.parquet" for code in codes_sorted}
    missing_codes = [c for c in codes_sorted if not cache_files[c].exists()]

    lg = None
    if missing_codes:
        print('ğŸ”Œ ç™»å½• baostock...', flush=True)
        lg = bs.login()
        if lg.error_code != '0':
            raise SystemExit('baostock login failed: ' + lg.error_msg)
    else:
        print('ğŸ—„ï¸ ç¼“å­˜é½å…¨ï¼Œè·³è¿‡è¡Œæƒ…ä¸‹è½½ï¼Œç›´æ¥è¯»å–æœ¬åœ°ã€‚', flush=True)

    for idx, code in enumerate(codes_sorted, 1):
        if idx % 200 == 0:
            print(f'è¿›åº¦ {idx}/{len(codes_sorted)} ...', flush=True)
        start, end = code_ranges[code]
        mkt = code.split('.')[-1].lower(); base = code.split('.')[0]
        bs_code = f"{mkt}.{base}"
        cache_file = cache_files[code]

        if cache_file.exists():
            md = pd.read_parquet(cache_file)
            md.index = pd.to_datetime(md.index)
        elif lg is not None:
            rs = bs.query_history_k_data_plus(bs_code, 'date,time,open,high,low,close,volume',
                                              start_date=start, end_date=end, frequency='5')
            data = []
            while rs.error_code == '0' and rs.next():
                data.append(rs.get_row_data())
            if not data:
                continue
            cdf = pd.DataFrame(data, columns=rs.fields)
            cdf['datetime'] = pd.to_datetime(cdf['date'] + ' ' + cdf['time'].str[8:10] + ':' + cdf['time'].str[10:12] + ':' + cdf['time'].str[12:14])
            cdf[['open', 'high', 'low', 'close']] = cdf[['open', 'high', 'low', 'close']].astype(float)
            cdf.set_index('datetime', inplace=True)
            md = cdf[['high', 'low', 'open', 'close']]
            md.to_parquet(cache_file, index=True)
        else:
            continue

        trades = pairs[pairs['code'] == code]
        for _, row in trades.iterrows():
            # å…¨ä½“çª—å£
            es = md.loc[(md.index >= row['open_timestamp']) & (md.index <= row['open_timestamp'] + timedelta(minutes=T_GLOBAL))]
            if not es.empty:
                lo, hi = es['low'].min(), es['high'].max()
                er = 0.5 if hi == lo else ((hi - row['open_price']) / (hi - lo) if row['trade_type'] == 'short' else (row['open_price'] - lo) / (hi - lo))
                entries_g.append(er)
            xs = md.loc[(md.index >= row['close_timestamp']) & (md.index <= row['close_timestamp'] + timedelta(minutes=T_GLOBAL))]
            if not xs.empty:
                lo2, hi2 = xs['low'].min(), xs['high'].max()
                xr = 0.5 if hi2 == lo2 else ((row['close_price'] - lo2) / (hi2 - lo2) if row['trade_type'] == 'short' else (hi2 - row['close_price']) / (hi2 - lo2))
                exits_g.append(xr)
            # è¶…çŸ­å•çª—å£
            if row['holding_minutes_trading'] <= 10:
                es_s = md.loc[(md.index >= row['open_timestamp']) & (md.index <= row['open_timestamp'] + timedelta(minutes=T_SHORT))]
                if not es_s.empty:
                    loS, hiS = es_s['low'].min(), es_s['high'].max()
                    er_s = 0.5 if hiS == loS else ((hiS - row['open_price']) / (hiS - loS) if row['trade_type'] == 'short' else (row['open_price'] - loS) / (hiS - loS))
                    entries_s.append(er_s)
                xs_s = md.loc[(md.index >= row['close_timestamp']) & (md.index <= row['close_timestamp'] + timedelta(minutes=T_SHORT))]
                if not xs_s.empty:
                    loS2, hiS2 = xs_s['low'].min(), xs_s['high'].max()
                    xr_s = 0.5 if hiS2 == loS2 else ((row['close_price'] - loS2) / (hiS2 - loS2) if row['trade_type'] == 'short' else (hiS2 - row['close_price']) / (hiS2 - loS2))
                    exits_s.append(xr_s)

    if lg is not None:
        bs.logout()
    print('âœ… è¡Œæƒ…æŠ“å–ä¸è®¡ç®—å®Œæˆ', flush=True)
    print('æ ·æœ¬æ•°: global entry/exit =', len(entries_g), len(exits_g), '; short entry/exit =', len(entries_s), len(exits_s))

    hists = []
    for key, title, data in [
        ('entries_g', f'å…¨ä½“äº¤æ˜“ EntryRank (TÎ±={T_GLOBAL}åˆ†é’Ÿ, 5minè¡Œæƒ…, å…¨é‡)', entries_g),
        ('exits_g', f'å…¨ä½“äº¤æ˜“ ExitRank (TÎ±={T_GLOBAL}åˆ†é’Ÿ, 5minè¡Œæƒ…, å…¨é‡)', exits_g),
        ('entries_s', f'è¶…çŸ­å• EntryRank (æŒä»“<=10åˆ†é’Ÿ, TÎ±={T_SHORT}åˆ†é’Ÿ, 5minè¡Œæƒ…)', entries_s),
        ('exits_s', f'è¶…çŸ­å• ExitRank (æŒä»“<=10åˆ†é’Ÿ, TÎ±={T_SHORT}åˆ†é’Ÿ, 5minè¡Œæƒ…)', exits_s),
    ]:
        h = summarize_hist(data, key, title)
        if h is not None:
            hists.append(h)

    sample_counts = {
        'entries_g': len(entries_g),
        'exits_g': len(exits_g),
        'entries_s': len(entries_s),
        'exits_s': len(exits_s),
    }
    payload = {
        "meta": {
            "t_global": T_GLOBAL,
            "t_short": T_SHORT,
            "sample_counts": sample_counts,
            "generated_at": pd.Timestamp.utcnow().isoformat(),
        },
        "hists": hists,
    }
    RESULT_CACHE.parent.mkdir(parents=True, exist_ok=True)
    RESULT_CACHE.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f'ğŸ’¾ å·²å†™å…¥ç»“æœç¼“å­˜: {RESULT_CACHE}')

    stats_map = {h['key']: h.get('stats', {}) for h in hists}
    figs = [fig_from_hist(h) for h in hists]

fig_html_parts = [
    f.to_html(full_html=False, include_plotlyjs='cdn', default_width='100%', default_height='420px')
    for f in figs
]
charts_html = "\n".join(f"<div class='chart'>{h}</div>" for h in fig_html_parts)

REPORT_HTML.parent.mkdir(parents=True, exist_ok=True)

html_text = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>æ‹©æ—¶èƒ½åŠ›åˆ†å¸ƒï¼ˆbaostock 5minï¼Œå…¨é‡ï¼‰</title>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <style>
    :root {{ --bg: #f6f7fb; --card: #fff; --text: #1f2937; --muted: #6b7280; --shadow: 0 2px 10px rgba(0,0,0,0.06); }}
    body {{ margin: 0; padding: 0; font-family: "Helvetica", "Arial", sans-serif; background: var(--bg); color: var(--text); }}
    .page {{ max-width: 1180px; margin: 0 auto; padding: 20px; display: grid; gap: 14px; }}
    .card {{ background: var(--card); border-radius: 12px; padding: 14px 16px; box-shadow: var(--shadow); }}
    h1 {{ margin: 0 0 8px 0; font-size: 22px; }}
    h2 {{ margin: 0 0 10px 0; font-size: 17px; color: var(--text); }}
    p {{ margin: 6px 0; line-height: 1.6; color: #374151; }}
    .muted {{ color: var(--muted); font-size: 13px; }}
    .badges {{ display: flex; flex-wrap: wrap; gap: 8px; margin-top: 6px; }}
    .badge {{ display: inline-flex; align-items: center; padding: 2px 10px; border-radius: 999px; background: #e0f2fe; color: #1d4ed8; font-size: 12px; }}
    .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(220px, 1fr)); gap: 10px; }}
    .stat {{ background: #f9fafb; border-radius: 10px; padding: 10px 12px; border: 1px solid #e5e7eb; }}
    .stat .title {{ font-size: 13px; color: var(--muted); margin-bottom: 4px; }}
    .stat .value {{ font-size: 20px; font-weight: 700; color: var(--text); }}
    .stat .small {{ font-size: 13px; color: #374151; font-weight: 500; line-height: 1.5; }}
    .chart {{ margin-top: 10px; }}
    .section-title {{ font-weight: 700; margin-bottom: 6px; }}
    .note {{ font-size: 13px; color: #4b5563; margin-top: 6px; }}
  </style>
</head>
<body>
  <div class="page">
    <div class="card">
      <h1>âš¡ äº¤æ˜“æ‰§è¡Œåˆ†æï½œæ‹©æ—¶èƒ½åŠ›åˆ†å¸ƒ</h1>
      <div class="badges">
        <span class="badge">Entry/ExitRank</span>
        <span class="badge">baostock 5min</span>
        <span class="badge">TÎ± å…¨ä½“ {T_GLOBAL_USE} åˆ†é’Ÿ</span>
        <span class="badge">TÎ± è¶…çŸ­ {T_SHORT_USE} åˆ†é’Ÿ</span>
      </div>
      <p>å£å¾„ï¼šå…¨ä½“äº¤æ˜“ä½¿ç”¨çª—å£ TÎ±={T_GLOBAL_USE} åˆ†é’Ÿï¼›è¶…çŸ­å•ï¼ˆæŒä»“â‰¤10 åˆ†é’Ÿï¼‰ä½¿ç”¨çª—å£ TÎ±={T_SHORT_USE} åˆ†é’Ÿã€‚Rankâˆˆ[0,1]ï¼Œè¶Šæ¥è¿‘ 0 è¯´æ˜æ‹©æ—¶è¶Šå¥½ï¼›ç©ºå¤´å·²é•œåƒå¤„ç†ã€‚</p>
    </div>

    <div class="card">
      <h2>æ ·æœ¬ä¸æ¦‚è§ˆ</h2>
      <div class="grid">
        <div class="stat"><div class="title">å…¨ä½“ Entry æ ·æœ¬</div><div class="value">{sample_counts.get('entries_g', 0):,}</div></div>
        <div class="stat"><div class="title">å…¨ä½“ Exit æ ·æœ¬</div><div class="value">{sample_counts.get('exits_g', 0):,}</div></div>
        <div class="stat"><div class="title">è¶…çŸ­ Entry æ ·æœ¬</div><div class="value">{sample_counts.get('entries_s', 0):,}</div></div>
        <div class="stat"><div class="title">è¶…çŸ­ Exit æ ·æœ¬</div><div class="value">{sample_counts.get('exits_s', 0):,}</div></div>
      </div>
      <div class="grid" style="margin-top:10px;">
        <div class="stat"><div class="title">å…¨ä½“ Entry ç»Ÿè®¡</div><div class="small">{format_stats(stats_map.get('entries_g'))}</div></div>
        <div class="stat"><div class="title">å…¨ä½“ Exit ç»Ÿè®¡</div><div class="small">{format_stats(stats_map.get('exits_g'))}</div></div>
        <div class="stat"><div class="title">è¶…çŸ­ Entry ç»Ÿè®¡</div><div class="small">{format_stats(stats_map.get('entries_s'))}</div></div>
        <div class="stat"><div class="title">è¶…çŸ­ Exit ç»Ÿè®¡</div><div class="small">{format_stats(stats_map.get('exits_s'))}</div></div>
      </div>
      <p class="note">è¯´æ˜ï¼šæŒ‡æ ‡åŸºäºäº¤æ˜“æ—¶æ®µåˆ†é’Ÿæ•°ï¼›ç©ºå¤´ä»·æ ¼å·²é•œåƒï¼Œä¿è¯ Rank å¯æ¯”ã€‚</p>
    </div>

    <div class="card">
      <h2>åˆ†å¸ƒç›´æ–¹å›¾</h2>
      <p class="note">é‡‡ç”¨é¢„èšåˆåˆ†ç®±ï¼Œé¡µé¢è½»é‡å¯ç›´æ¥åµŒå…¥ iframeã€‚</p>
      {charts_html}
    </div>

    <div class="card">
      <h2 class="section-title">å®ç°æ–¹å¼</h2>
      <p>æ•°æ®æ¥æºï¼šè®¢å•é…å¯¹ data/paired_trades_fifo.parquetï¼›è¡Œæƒ…æ¥æºï¼šbaostock 5minï¼Œç¼“å­˜ç›®å½• data/cache/baostock_5minï¼ˆè‹¥æ–‡ä»¶å­˜åœ¨åˆ™å¤ç”¨ï¼Œä¸å†è¯·æ±‚ï¼‰ã€‚</p>
      <p>è®¡ç®—å£å¾„ï¼šå…¨ä½“äº¤æ˜“çª—å£ TÎ±={T_GLOBAL_USE} åˆ†é’Ÿï¼›è¶…çŸ­å•ï¼ˆæŒä»“â‰¤10 åˆ†é’Ÿï¼‰çª—å£ TÎ±={T_SHORT_USE} åˆ†é’Ÿã€‚Entry/ExitRank âˆˆ[0,1]ï¼Œ0=æ‹©æ—¶ä½³ã€1=æ‹©æ—¶å·®ï¼Œç©ºå¤´æ–¹å‘å·²é•œåƒã€‚</p>
      <h2 class="section-title">åˆ¶ä½œç›®çš„</h2>
      <p>ç”¨äºâ€œäº¤æ˜“æ‰§è¡Œåˆ†æâ€æ¿å—è¯Šæ–­å…¨ä½“ä¸è¶…çŸ­å•çš„æ‹©æ—¶åˆ†å¸ƒï¼Œæ”¯æŒåç»­ä¸æŒ‡æ•°æˆ–åŸºå‡†ç›˜é¢æ¨ªå‘å¯¹æ¯”ã€‚</p>
      <p class="note">å¦‚éœ€æ›´æ–°ï¼Œè¿è¡Œ scripts/run_entry_exit_rank_baostock.pyï¼ˆè‡ªåŠ¨ç”Ÿæˆå¹¶å¤åˆ¶åˆ° reports/visualization_analysis/ ä¸ docs/ï¼›è‹¥ç®—æ³•æˆ–çª—å£æ”¹åŠ¨è¯·åŠ  --recompute æˆ–åˆ é™¤ç»“æœç¼“å­˜ {RESULT_CACHE}ï¼‰ã€‚</p>
    </div>
  </div>
</body>
</html>
"""

REPORT_HTML.write_text(html_text, encoding='utf-8')
REPORT_TXT.write_text(
    f'global_entry={sample_counts.get("entries_g",0)}, global_exit={sample_counts.get("exits_g",0)}, short_entry={sample_counts.get("entries_s",0)}, short_exit={sample_counts.get("exits_s",0)}\n',
    encoding='utf-8'
)
print('ğŸ¯ è¾“å‡º:', REPORT_HTML, REPORT_TXT)
# å¤åˆ¶åˆ°å¯è§†åŒ–/å‘å¸ƒç›®å½•ï¼Œæ–¹ä¾¿ iframe å¼•ç”¨
for tgt in COPY_HTML_TARGETS:
    try:
        tgt.parent.mkdir(parents=True, exist_ok=True)
        tgt.write_text(REPORT_HTML.read_text(encoding='utf-8'), encoding='utf-8')
    except Exception as e:
        print(f'âš ï¸ æ‹·è´åˆ° {tgt} å¤±è´¥: {e}')
